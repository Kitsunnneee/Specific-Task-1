{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9mhkg7S7B+5dFTRDg9K+T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kitsunnneee/Specific-Task-1/blob/main/Specific_Task_1(Contrastive_Learning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwO4dQ1Q7jbX"
      },
      "source": [
        "# Installing all the neccessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLlBp4jg3lze",
        "outputId": "09a09fbb-18bb-4983-efaf-a9d403c47cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyGCL\n",
            "  Downloading PyGCL-0.1.2-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from PyGCL) (2.2.1+cu121)\n",
            "Requirement already satisfied: torch-geometric>=1.7 in /usr/local/lib/python3.10/dist-packages (from PyGCL) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from PyGCL) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from PyGCL) (4.66.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from PyGCL) (1.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from PyGCL) (3.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from PyGCL) (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->PyGCL) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->PyGCL) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->PyGCL) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->PyGCL) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->PyGCL) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->PyGCL) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->PyGCL)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric>=1.7->PyGCL) (3.9.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric>=1.7->PyGCL) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric>=1.7->PyGCL) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric>=1.7->PyGCL) (2.31.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->PyGCL) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->PyGCL) (3.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric>=1.7->PyGCL) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric>=1.7->PyGCL) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric>=1.7->PyGCL) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric>=1.7->PyGCL) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric>=1.7->PyGCL) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric>=1.7->PyGCL) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->PyGCL) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric>=1.7->PyGCL) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric>=1.7->PyGCL) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric>=1.7->PyGCL) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric>=1.7->PyGCL) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->PyGCL) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, PyGCL\n",
            "Successfully installed PyGCL-0.1.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-2.1.0\n",
            "Collecting pytorch_metric_learning\n",
            "  Downloading pytorch_metric_learning-2.4.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->pytorch_metric_learning) (12.4.99)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch_metric_learning) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch_metric_learning) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch_metric_learning) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch_metric_learning) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch_metric_learning) (1.3.0)\n",
            "Installing collected packages: pytorch_metric_learning\n",
            "Successfully installed pytorch_metric_learning-2.4.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "!pip install h5py\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install PyGCL\n",
        "!pip install dgl\n",
        "!pip install pytorch_metric_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UehXYuf7xFm"
      },
      "source": [
        "# Importing all the neccessary dependencies\n",
        "Note : This project uses PyTorch Geometric Contrastive Learning(PyGCL), a PyTorch-based, library for all the Graph Contrastive learning task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dAY3JALT3tKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e132dd7-b828-4883-ffbf-cf8f2ff9821c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, ReLU\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import GCL.augmentors as A\n",
        "import GCL.losses as L\n",
        "from GCL.models import DualBranchContrast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCS3Vnr_8K9i"
      },
      "source": [
        "# Mounting and Loading the data from Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2cGtsP2O3v0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c974d55-cbf1-4c9e-b03a-76498dbbf609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x2n4PRHx3xpA"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/quark-gluon_data-set_n139306.hdf5\" #Path to the dataset on my google drive\n",
        "\n",
        "with h5py.File(path, 'r') as f:\n",
        "  X_jets = np.array(f['X_jets'][:8000])\n",
        "  labels = np.array(f['y'][:8000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx2lJY4W8Vum"
      },
      "source": [
        "# Converting the data to Graph format and doing preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UanBEquA31RN"
      },
      "outputs": [],
      "source": [
        "dataset = []\n",
        "for i, x in enumerate(X_jets):\n",
        "  flattened = x.reshape(-1,3)\n",
        "  non_zero = np.any(flattened != (0,0,0), axis = -1) # Removing any zero element by considering only non zero ones\n",
        "  node = flattened[non_zero]\n",
        "  edges = kneighbors_graph(node, 2, mode = 'connectivity',include_self = True)\n",
        "  edges = edges.tocoo()\n",
        "  y = torch.tensor([int(labels[i])], dtype=torch.long)\n",
        "  data = Data(x=torch.from_numpy(node), edge_index=torch.from_numpy(np.vstack((edges.row,edges.col))).type(torch.long), edge_attr=torch.from_numpy(edges.data.reshape(-1,1)), y=y)\n",
        "  dataset.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NjpJ31Ph34jL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41df8b47-a35d-4a36-f86f-f4419d004e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of graphs: 8000\n",
            "Number of nodes: 884\n",
            "Number of edges: 1768\n",
            "Number of node features: 3\n",
            "Number of edges features: 1\n",
            "Data(x=[884, 3], edge_index=[2, 1768], edge_attr=[1768, 1], y=[1])\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of nodes: {dataset[0].num_nodes}')\n",
        "print(f'Number of edges: {dataset[0].num_edges}')\n",
        "print(f'Number of node features: {dataset[0].num_node_features}')\n",
        "print(f'Number of edges features: {dataset[0].num_edge_features}')\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wOPGh7do36Ne"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset[:5000], batch_size=8, shuffle=True)  #Creating the train loader with batch = 8\n",
        "test_loader = DataLoader(dataset[5000:], batch_size=8, shuffle=False) # Creating the test loader with batch = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MUe2ltCWEVP1"
      },
      "outputs": [],
      "source": [
        "aug = A.Compose([A.EdgeRemoving(pe=0.3), A.FeatureMasking(pf=0.3)]) # Selecing the graph augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cdQYMNstEtW3"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucaooTl-85YT"
      },
      "source": [
        "# Creating the Contrastive model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "knK7XIXVus-A"
      },
      "outputs": [],
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, xavier=True):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.conv1 = GCNConv(3, 32)\n",
        "        self.conv2 = GCNConv(32, 32)\n",
        "        self.fc1 = Linear(32, 32)\n",
        "        self.fc2 = Linear(32, 32)\n",
        "        self.act = ReLU()\n",
        "\n",
        "    def forward(self, data):\n",
        "          # Performing the augmentaion twice as we use dual branch contrastive learning\n",
        "          augm_1 = aug(data.x, data.edge_index)\n",
        "          augm_2 = aug(data.x, data.edge_index)\n",
        "\n",
        "          x1 = self.conv1(augm_1[0], augm_1[1])\n",
        "          x1 = self.act(x1)\n",
        "          x2 = self.conv2(x1, augm_1[1])\n",
        "          z1 = self.act(x2)\n",
        "\n",
        "          x1 = self.conv1(augm_2[0], augm_2[1])\n",
        "          x1 = self.act(x1)\n",
        "          x2 = self.conv2(x2, augm_2[1])\n",
        "          z2 = self.act(x2)\n",
        "\n",
        "          x1 = self.conv1(data.x, data.edge_index)\n",
        "          x1 = self.act(x1)\n",
        "          x2 = self.conv2(x1, data.edge_index)\n",
        "          z = self.act(x2)\n",
        "\n",
        "          return z, z1, z2\n",
        "\n",
        "    def project(self, z: torch.Tensor) -> torch.Tensor:\n",
        "          #Projection head to reduce the size of the embeddings\n",
        "          z = F.elu(self.fc1(z))\n",
        "          return self.fc2(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ayn4PhO9dpc"
      },
      "source": [
        "# Training the contrastive learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1fy5cIaLxR95"
      },
      "outputs": [],
      "source": [
        "def train(encoder_model, contrast_model, data, optimizer):\n",
        "    encoder_model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z, z1, z2 = encoder_model(data)\n",
        "    h1, h2 = [encoder_model.project(x) for x in [z1, z2]] # Creating the reduced embeddings for the contrastive learning\n",
        "    loss = contrast_model(h1, h2)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "k3z0sRrQrJoj"
      },
      "outputs": [],
      "source": [
        "def test(encoder_model, contrast_mocel, data, optimizer):\n",
        "    encoder_model.eval()\n",
        "    z, z1, z2 = encoder_model(data)\n",
        "    h1, h2 = [encoder_model.project(x) for x in [z1, z2]] # Creating the reduced embeddings for the contrastive learning\n",
        "    loss = contrast_model(h1, h2)\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qzyLdU6dsqAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c31239-a1d7-496d-edb7-64bbe8f625f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/625 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead\n",
            "  warnings.warn(out)\n",
            "100%|██████████| 625/625 [00:35<00:00, 17.83it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 8.071, Test Loss: 7.537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.04it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 7.330, Test Loss: 6.931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.10it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train Loss: 6.880, Test Loss: 7.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.11it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train Loss: 6.609, Test Loss: 6.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.14it/s]\n",
            "100%|██████████| 375/375 [00:18<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Train Loss: 6.332, Test Loss: 6.410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:33<00:00, 18.76it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train Loss: 6.679, Test Loss: 7.155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:33<00:00, 18.80it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Train Loss: 6.109, Test Loss: 6.331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.08it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Train Loss: 7.140, Test Loss: 6.191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 18.96it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Train Loss: 6.235, Test Loss: 6.098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.15it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Train Loss: 5.790, Test Loss: 5.789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 18.94it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 6.492, Test Loss: 6.982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.23it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Train Loss: 6.332, Test Loss: 6.913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.07it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Train Loss: 6.874, Test Loss: 5.855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.21it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Train Loss: 5.663, Test Loss: 6.481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:33<00:00, 18.64it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Train Loss: 7.655, Test Loss: 6.290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 18.96it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Train Loss: 5.518, Test Loss: 5.478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:33<00:00, 18.90it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Train Loss: 5.534, Test Loss: 5.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.06it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Train Loss: 6.940, Test Loss: 5.489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:33<00:00, 18.84it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Train Loss: 5.568, Test Loss: 5.293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 18.96it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Train Loss: 5.250, Test Loss: 5.292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:33<00:00, 18.72it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Train Loss: 6.022, Test Loss: 5.888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:33<00:00, 18.94it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Train Loss: 5.067, Test Loss: 5.232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 18.94it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Train Loss: 5.423, Test Loss: 6.408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.22it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Train Loss: 6.304, Test Loss: 5.331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.08it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Train Loss: 5.226, Test Loss: 5.331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.23it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Train Loss: 5.049, Test Loss: 5.108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.12it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 29.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Train Loss: 5.934, Test Loss: 5.471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.22it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Train Loss: 5.156, Test Loss: 5.101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.17it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Train Loss: 5.307, Test Loss: 5.306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:32<00:00, 19.25it/s]\n",
            "100%|██████████| 375/375 [00:12<00:00, 30.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Train Loss: 5.166, Test Loss: 6.304\n",
            "Encoder weights saved successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "encoder_model = GCN().to(device)\n",
        "#Using Dual Branch Contrastive Learning with InfoNCE loss and using local-to-local mode[to learn local representation]\n",
        "contrast_model = DualBranchContrast(loss=L.InfoNCE(tau=0.2), mode='L2L').to(device)\n",
        "optimizer = Adam(encoder_model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(30):\n",
        "  total_loss = 0\n",
        "  for _, data in enumerate(tqdm.tqdm(train_loader)):\n",
        "      data = data.to(device)\n",
        "      train_loss = train(encoder_model, contrast_model, data, optimizer)\n",
        "  for _, data in enumerate(tqdm.tqdm(test_loader)):\n",
        "      data = data.to(device)\n",
        "      test_loss = test(encoder_model, contrast_model, data, optimizer)\n",
        "\n",
        "  log = \"Epoch {}, Train Loss: {:.3f}, Test Loss: {:.3f}\"\n",
        "  print(log.format(epoch, train_loss, test_loss))\n",
        "\n",
        "#Save Model\n",
        "torch.save(encoder_model.state_dict(), 'autoencoder_weights.pth')\n",
        "print(\"Encoder weights saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMcxYtNh-BwO"
      },
      "source": [
        "# Defining the classifcation model\n",
        "Here we use the model defined for learning representation before but without the projection head as we only need the learned represntation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MwmRy1OXgl2S"
      },
      "outputs": [],
      "source": [
        "class GraphClassificationModel(nn.Module):\n",
        "    def __init__(self, load=True):\n",
        "        super(GraphClassificationModel, self).__init__()\n",
        "\n",
        "        self.encoder = GCN().to(device)\n",
        "\n",
        "        if load:\n",
        "            pth = self.encoder.load_state_dict(torch.load('autoencoder_weights.pth'))\n",
        "            for param in self.encoder.parameters():\n",
        "                param.requires_grad = False # Freezing the learned weights of encoder\n",
        "\n",
        "        self.classifier = nn.Linear(32, 2)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        embeddings,_,_ = self.encoder(data)\n",
        "        z = global_mean_pool(embeddings, batch)\n",
        "        pred = self.classifier(z)\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCATIkMr-YdZ"
      },
      "source": [
        "# Training and Testing of the Classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wHxoJh_HjoDY"
      },
      "outputs": [],
      "source": [
        "def train_classification(model, loader, optimizer, criterion):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  total_samples = 0\n",
        "  for _, data in enumerate(tqdm.tqdm(train_loader)):\n",
        "    # print(data.batch.size)\n",
        "    data = data.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    #print(out.shape)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item() * data.num_graphs\n",
        "    # Calculate train accuracy\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct += (pred == data.y).sum().item()\n",
        "    total_samples += data.num_graphs\n",
        "  train_accuracy = correct / total_samples\n",
        "  return total_loss / len(loader.dataset), train_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4MUWhDMLwNzf"
      },
      "outputs": [],
      "source": [
        "def test_classification(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == data.y).sum().item() #Calculating the correct predictions\n",
        "            total += data.num_graphs\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbzRcmrsn3LT",
        "outputId": "f55cb698-801b-41e7-8249-e58eac5d36e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:06<00:00, 103.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 0.6547, Train Accuracy: 0.6292, Test Accuracy: 0.6143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 113.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train Loss: 0.6370, Train Accuracy: 0.6598, Test Accuracy: 0.6507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:06<00:00, 102.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train Loss: 0.6361, Train Accuracy: 0.6620, Test Accuracy: 0.5960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 119.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Train Loss: 0.6309, Train Accuracy: 0.6676, Test Accuracy: 0.6873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 122.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train Loss: 0.6304, Train Accuracy: 0.6682, Test Accuracy: 0.6447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 107.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Train Loss: 0.6360, Train Accuracy: 0.6688, Test Accuracy: 0.6750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 123.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Train Loss: 0.6305, Train Accuracy: 0.6658, Test Accuracy: 0.6917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 119.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Train Loss: 0.6343, Train Accuracy: 0.6710, Test Accuracy: 0.6930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:06<00:00, 98.48it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Train Loss: 0.6294, Train Accuracy: 0.6692, Test Accuracy: 0.6357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 113.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 0.6240, Train Accuracy: 0.6686, Test Accuracy: 0.6013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 114.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Train Loss: 0.6328, Train Accuracy: 0.6702, Test Accuracy: 0.6217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 104.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Train Loss: 0.6187, Train Accuracy: 0.6754, Test Accuracy: 0.6733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 117.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Train Loss: 0.6382, Train Accuracy: 0.6680, Test Accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 108.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Train Loss: 0.6324, Train Accuracy: 0.6718, Test Accuracy: 0.6480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 107.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Train Loss: 0.6332, Train Accuracy: 0.6734, Test Accuracy: 0.6827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 122.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Train Loss: 0.6249, Train Accuracy: 0.6762, Test Accuracy: 0.5250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 117.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Train Loss: 0.6292, Train Accuracy: 0.6746, Test Accuracy: 0.6940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 108.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Train Loss: 0.6268, Train Accuracy: 0.6764, Test Accuracy: 0.6627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 123.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Train Loss: 0.6281, Train Accuracy: 0.6730, Test Accuracy: 0.7013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 625/625 [00:05<00:00, 110.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Train Loss: 0.6274, Train Accuracy: 0.6752, Test Accuracy: 0.7027\n"
          ]
        }
      ],
      "source": [
        "model = GraphClassificationModel().to(device)\n",
        "optimizer_2 = Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(20):\n",
        "    train_loss, train_accuracy = train_classification(model, train_loader, optimizer_2, criterion)\n",
        "    test_accuracy = test_classification(model, test_loader)\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWrDxtOuBPWz"
      },
      "source": [
        "# Conclusion\n",
        "The model's accuracy is 70% which is not the best. There are a multitude of reasons for that.\n",
        "\n",
        "- One big problem is graph-level representation. Although, I have used global pooling to get a graph-level representation that is not the best way.\n",
        "\n",
        "- We only consider an extremely small subset of the actual data due to memory issues which may cause data imbalance which stops the model from learning properly.\n",
        "\n",
        "- Another problem is the graph representation isn't being learned well. Many possible reasons can be for this such as the architecture may not be right, the parameter tuning needs to be done well, etc. Further Research into this is required.\n",
        "\n",
        "- When constructing the contrastive learning architecture other Graph models may be used such as GAT, GraphSage, etc  to learn the representation. Each of these models will learn a different representation for the node which may be better or worse but may increase the complexity of the model which may be computationally inefficient for larger datasets and graphs or also decrease.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}