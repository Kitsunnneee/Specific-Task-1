{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing all the neccessary dependencies"
      ],
      "metadata": {
        "id": "bwO4dQ1Q7jbX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLlBp4jg3lze"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "!pip install h5py\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install PyGCL\n",
        "!pip install dgl\n",
        "!pip install pytorch_metric_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing all the neccessary dependencies\n",
        "Note : This project uses PyTorch Geometric Contrastive Learning(PyGCL), a PyTorch-based, library for all the Contrastive learning task."
      ],
      "metadata": {
        "id": "3UehXYuf7xFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, ReLU\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import GCL.augmentors as A\n",
        "import GCL.losses as L\n",
        "from GCL.models import DualBranchContrast"
      ],
      "metadata": {
        "id": "dAY3JALT3tKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting and Loading the data from Drive"
      ],
      "metadata": {
        "id": "OCS3Vnr_8K9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cGtsP2O3v0V",
        "outputId": "98d2b5a8-203f-4e89-ffc8-3a4755d9f40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/quark-gluon_data-set_n139306.hdf5\" #Path to the dataset on my google drive\n",
        "\n",
        "with h5py.File(path, 'r') as f:\n",
        "  X_jets = f['X_jets'][0:4000] # Working with only a subset of data due to computational limits\n",
        "  y = f['y'][0:4000]\n",
        "  print(f\"X_jets shape : {X_jets.shape}, y : {y.shape}\") # printing the shape of the images and amount"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2n4PRHx3xpA",
        "outputId": "84aa6d7f-cf6a-41b9-8223-d36359286762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_jets shape : (4000, 125, 125, 3), y : (4000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_jets = np.array(X_jets)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "k6iyLBAP3zV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting the data to Graph format and doing preprocessing"
      ],
      "metadata": {
        "id": "Fx2lJY4W8Vum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "\n",
        "for i, x in enumerate(X_jets):\n",
        "  flattened = x.reshape(-1,3)\n",
        "  non_zero = np.any(flattened != (0,0,0), axis = -1) # Removing any zero element by considering only non zero ones\n",
        "  node = flattened[non_zero]\n",
        "  edges = kneighbors_graph(node, 2, mode = 'connectivity',include_self = True)\n",
        "  edges = edges.tocoo()\n",
        "  data = Data(x=torch.from_numpy(node), edge_index=torch.from_numpy(np.vstack((edges.row,edges.col))).type(torch.long), edge_attr=torch.from_numpy(edges.data.reshape(-1,1)), y=torch.tensor([int(y[i])]))\n",
        "  dataset.append(data)"
      ],
      "metadata": {
        "id": "UanBEquA31RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of nodes: {dataset[0].num_nodes}')\n",
        "print(f'Number of edges: {dataset[0].num_edges}')\n",
        "print(f'Number of node features: {dataset[0].num_node_features}')\n",
        "print(f'Number of edges features: {dataset[0].num_edge_features}')\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjpJ31Ph34jL",
        "outputId": "1d85231e-3e43-42c9-cc79-da2cb63614df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of graphs: 4000\n",
            "Number of nodes: 884\n",
            "Number of edges: 1768\n",
            "Number of node features: 3\n",
            "Number of edges features: 1\n",
            "Data(x=[884, 3], edge_index=[2, 1768], edge_attr=[1768, 1], y=[1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset[:1000], batch_size=8, shuffle=True)  #Creating the train loader with batch = 8\n",
        "test_loader = DataLoader(dataset[1000:2000], batch_size=8, shuffle=False) # Creating the test loader with batch = 8"
      ],
      "metadata": {
        "id": "wOPGh7do36Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug = A.Compose([A.EdgeRemoving(pe=0.3), A.FeatureMasking(pf=0.3)]) # Selecing the graph augmentations"
      ],
      "metadata": {
        "id": "MUe2ltCWEVP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "cdQYMNstEtW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Contrastive model"
      ],
      "metadata": {
        "id": "ucaooTl-85YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.conv1 = GCNConv(3, 32)\n",
        "        self.conv2 = GCNConv(32, 32)\n",
        "        self.fc1 = Linear(32, 32)\n",
        "        self.fc2 = Linear(32, 32)\n",
        "        self.act = ReLU()\n",
        "\n",
        "    def forward(self, data):\n",
        "          # Performing the augmentaion twice as we use dual branch contrastive learning\n",
        "          augm_1 = aug(data.x, data.edge_index)\n",
        "          augm_2 = aug(data.x, data.edge_index)\n",
        "\n",
        "          x1 = self.conv1(augm_1[0], augm_1[1])\n",
        "          x1 = self.act(x1)\n",
        "          x2 = self.conv2(x1, augm_1[1])\n",
        "          z1 = self.act(x2)\n",
        "\n",
        "          x1 = self.conv1(augm_2[0], augm_2[1])\n",
        "          x1 = self.act(x1)\n",
        "          x2 = self.conv2(x2, augm_2[1])\n",
        "          z2 = self.act(x2)\n",
        "\n",
        "          x1 = self.conv1(data.x, data.edge_index)\n",
        "          x1 = self.act(x1)\n",
        "          x2 = self.conv2(x1, data.edge_index)\n",
        "          z = self.act(x2)\n",
        "\n",
        "          return z, z1, z2\n",
        "\n",
        "    def project(self, z: torch.Tensor) -> torch.Tensor:\n",
        "          #Projection head to reduce the size of the embeddings\n",
        "          z = F.elu(self.fc1(z))\n",
        "          return self.fc2(z)"
      ],
      "metadata": {
        "id": "knK7XIXVus-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the contrastive learning model"
      ],
      "metadata": {
        "id": "2ayn4PhO9dpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(encoder_model, contrast_model, data, optimizer):\n",
        "    encoder_model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z, z1, z2 = encoder_model(data)\n",
        "    h1, h2 = [encoder_model.project(x) for x in [z1, z2]] # Creating the reduced embeddings for the contrastive learning\n",
        "    loss = contrast_model(h1, h2)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "1fy5cIaLxR95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = GCN().to(device)\n",
        "#Using Dual Branch Contrastive Learning with InfoNCE loss and using local-to-local mode[to learn local representation]\n",
        "contrast_model = DualBranchContrast(loss=L.InfoNCE(tau=0.2), mode='L2L').to(device)\n",
        "\n",
        "optimizer = Adam(encoder_model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(30):\n",
        "  total_loss = 0\n",
        "  for _, data in enumerate(tqdm.tqdm(train_loader)):\n",
        "      data = data.to(device)\n",
        "      loss = train(encoder_model, contrast_model, data, optimizer)\n",
        "      total_loss += loss * data.num_graphs\n",
        "  print(f'Epoch {epoch:03d}, Loss: {total_loss/len(train_loader.dataset):.4f}')"
      ],
      "metadata": {
        "id": "qzyLdU6dsqAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ce4416-4878-4987-ad4f-47e4a73a7750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/125 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead\n",
            "  warnings.warn(out)\n",
            "100%|██████████| 125/125 [00:07<00:00, 17.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 000, Loss: 8.1647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001, Loss: 7.9752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 002, Loss: 7.9306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 003, Loss: 7.8618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 004, Loss: 7.6426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 005, Loss: 7.6531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 006, Loss: 7.5355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 007, Loss: 7.4389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 008, Loss: 7.3446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 009, Loss: 7.3140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010, Loss: 7.2173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 011, Loss: 7.1093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 18.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 012, Loss: 7.2032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 18.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 013, Loss: 7.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 014, Loss: 7.1036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 015, Loss: 7.1141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 016, Loss: 7.1741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 18.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 017, Loss: 7.0800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 018, Loss: 7.0694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 019, Loss: 7.0422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 020, Loss: 6.9561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 021, Loss: 7.0563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 022, Loss: 6.9543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 023, Loss: 6.8769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 024, Loss: 6.8457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 025, Loss: 6.7956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 026, Loss: 6.8292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 027, Loss: 6.7919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 028, Loss: 6.8415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:06<00:00, 19.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 029, Loss: 6.8689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the classifcation model\n",
        "Here we use the model defined for learning representation before but without the projection head as we only need the learned represntation"
      ],
      "metadata": {
        "id": "cMcxYtNh-BwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNWithClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCNWithClassifier, self).__init__()\n",
        "        self.gcn = GCN()\n",
        "        self.classifier = Linear(32, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        z, _, _ = self.gcn(data)  # Using GCN model to get embeddings\n",
        "        x = global_mean_pool(z, data.batch) # Using global pooling to get a global representation of a graph\n",
        "        out = self.classifier(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "MwmRy1OXgl2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing of the Classification model"
      ],
      "metadata": {
        "id": "WCATIkMr-YdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classification(model, loader, optimizer, criterion):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for data in loader:\n",
        "    data = data.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item() * data.num_graphs\n",
        "\n",
        "  return total_loss / len(loader.dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "wHxoJh_HjoDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_classification(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == data.y).sum().item() #Calculating the correct predictions\n",
        "            total += data.num_graphs\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "4MUWhDMLwNzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCNWithClassifier().to(device)\n",
        "optimizer_2 = Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(20):\n",
        "    loss = train_classification(model, train_loader, optimizer_2, criterion)\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss:.4f}')\n",
        "    train_acc = test_classification(model, train_loader)\n",
        "    print(f'Train Accuracy: {train_acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbzRcmrsn3LT",
        "outputId": "9d068337-e956-431b-bd93-f9ebf4810ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6936\n",
            "Train Accuracy: 0.5180\n",
            "Epoch 2, Loss: 0.6609\n",
            "Train Accuracy: 0.6790\n",
            "Epoch 3, Loss: 0.6271\n",
            "Train Accuracy: 0.6890\n",
            "Epoch 4, Loss: 0.6187\n",
            "Train Accuracy: 0.6660\n",
            "Epoch 5, Loss: 0.6182\n",
            "Train Accuracy: 0.6550\n",
            "Epoch 6, Loss: 0.6166\n",
            "Train Accuracy: 0.6870\n",
            "Epoch 7, Loss: 0.6172\n",
            "Train Accuracy: 0.6800\n",
            "Epoch 8, Loss: 0.6132\n",
            "Train Accuracy: 0.6630\n",
            "Epoch 9, Loss: 0.6204\n",
            "Train Accuracy: 0.6720\n",
            "Epoch 10, Loss: 0.6158\n",
            "Train Accuracy: 0.6650\n",
            "Epoch 11, Loss: 0.6159\n",
            "Train Accuracy: 0.6700\n",
            "Epoch 12, Loss: 0.6163\n",
            "Train Accuracy: 0.6760\n",
            "Epoch 13, Loss: 0.6181\n",
            "Train Accuracy: 0.6540\n",
            "Epoch 14, Loss: 0.6149\n",
            "Train Accuracy: 0.6830\n",
            "Epoch 15, Loss: 0.6177\n",
            "Train Accuracy: 0.6670\n",
            "Epoch 16, Loss: 0.6199\n",
            "Train Accuracy: 0.6740\n",
            "Epoch 17, Loss: 0.6173\n",
            "Train Accuracy: 0.6810\n",
            "Epoch 18, Loss: 0.6164\n",
            "Train Accuracy: 0.6460\n",
            "Epoch 19, Loss: 0.6171\n",
            "Train Accuracy: 0.6700\n",
            "Epoch 20, Loss: 0.6165\n",
            "Train Accuracy: 0.6850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = test_classification(model, test_loader) #Calculating the testing accuracy\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlOrHc0zqw44",
        "outputId": "bdbd8667-d38f-4bb9-c553-2544e4cbd9b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "The model's accuracy is 68% which is not the best. There are a multitude of reasons for that.\n",
        "\n",
        "\n",
        "\n",
        "*   One big problem is graph level representation. Although, I have used global pooling to get a graph level representation that is not the best way.\n",
        "\n",
        "*   We only consider an extremely small subset of the actual data due to memory issues which may cause data imbalance which stops the model from learning properly.\n",
        "\n",
        "* Another problem is the graph representation itself. When we convert the image to graph the node features or the deciding the edge features is an important task. Here, I take only the value of the 3 channels(Tracks, ECAL or HCAL) as node features but in related work people have takes the position of the pixels as node features or we can take momentum etc.\n",
        "\n",
        "* When constructing the contrastive learning model other Graph models may be used such as GAT, GraphSage or Edge Convolution to learn the represntation. Each of these models will learn a better representation of the neighbour but would increase the complexity of the model which maybe computationally inefficient for larger dataset and graphs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WWrDxtOuBPWz"
      }
    }
  ]
}